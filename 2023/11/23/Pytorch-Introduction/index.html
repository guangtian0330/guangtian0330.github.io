<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Pytorch Introduction--Tensor - Guangtian&#039;s BLOG</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Tian&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Tian&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="1. What is PyTorchPyTorch is a Python-based scientific computing package, which can be used to:  Replace NumPy to use the power of GPUs and other accelerators; Using the GPU for deep learning computat"><meta property="og:type" content="blog"><meta property="og:title" content="Pytorch Introduction--Tensor"><meta property="og:url" content="http://example.com/2023/11/23/Pytorch-Introduction/"><meta property="og:site_name" content="Peaceland"><meta property="og:description" content="1. What is PyTorchPyTorch is a Python-based scientific computing package, which can be used to:  Replace NumPy to use the power of GPUs and other accelerators; Using the GPU for deep learning computat"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:published_time" content="2023-11-23T20:37:00.000Z"><meta property="article:modified_time" content="2023-11-23T23:09:01.815Z"><meta property="article:author" content="Guangtian"><meta property="article:tag" content="pytorch"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2023/11/23/Pytorch-Introduction/"},"headline":"Pytorch Introduction--Tensor","image":["http://example.com/img/og_image.png"],"datePublished":"2023-11-23T20:37:00.000Z","dateModified":"2023-11-23T23:09:01.815Z","author":{"@type":"Person","name":"Guangtian"},"publisher":{"@type":"Organization","name":"Guangtian's BLOG","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"1. What is PyTorchPyTorch is a Python-based scientific computing package, which can be used to:  Replace NumPy to use the power of GPUs and other accelerators; Using the GPU for deep learning computat"}</script><link rel="canonical" href="http://example.com/2023/11/23/Pytorch-Introduction/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Guangtian&#039;s BLOG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Visit Github" href="https://github.com/guangtian0330"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-11-23T20:37:00.000Z" title="2023/11/23 15:37:00">2023-11-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-11-23T23:09:01.815Z" title="2023/11/23 18:09:01">2023-11-23</time></span><span class="level-item">5 minutes read (About 708 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Pytorch Introduction--Tensor</h1><div class="content"><h4 id="1-What-is-PyTorch"><a href="#1-What-is-PyTorch" class="headerlink" title="1. What is PyTorch"></a>1. What is PyTorch</h4><p>PyTorch is a Python-based scientific computing package, which can be used to:</p>
<ol>
<li><p>Replace NumPy to use the power of GPUs and other accelerators;</p>
<p>Using the GPU for deep <strong>learning computations</strong> can significantly speed up the training process because the GPU is designed to handle <strong>parallel computations</strong>, which are common in deep learning tasks. However, it’s important to note that not all operations are automatically faster on the GPU. Some operations might actually be slower due to the <strong>overhead of transferring data</strong> between the CPU and GPU. </p>
<p>Typically, <strong>large matrix multiplications</strong> and other <strong>computationally intensive</strong> operations benefit the most from GPU acceleration.</p>
</li>
<li><p>support automatic differentiation functions to implement neural networks.</p>
</li>
</ol>
<h4 id="2-What-is-Tensor"><a href="#2-What-is-Tensor" class="headerlink" title="2. What is Tensor"></a>2. What is Tensor</h4><p>Tensors are a data structure similar to Numpy’s ndarrays and matrices. It’s used to encode the inputs and outputs, as well as models’ parameters.  Tensors can run on GPUs or other specialized hardware to accelerate computing.</p>
<h5 id="2-1-Initialization-of-Tensor"><a href="#2-1-Initialization-of-Tensor" class="headerlink" title="2.1 Initialization of Tensor"></a>2.1 Initialization of Tensor</h5><p>There are 4 ways commonly used to initialize the Tensor:</p>
<ol>
<li><p>Directly from data, so the data type is automatically inferred.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">3</span>]]</span><br><span class="line">x_data = torch.tensor(data)</span><br></pre></td></tr></table></figure>
</li>
<li><p>From a NumPy array</p>
<p>a) NumPy array to Tensor</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">array_data = np.array(data)</span><br><span class="line">tensor_data = torch.from_numpy(array_data)</span><br></pre></td></tr></table></figure>

<p>b) Tensor to NumPy array</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor_ones = torch.ones(<span class="number">5</span>)</span><br><span class="line">numpy_data = tensor_ones.numpy()</span><br></pre></td></tr></table></figure>
</li>
<li><p>From another tensor</p>
<p>The new tensor retains the properties(shape, datatype) of the argument tensor, unless explicitly overridden.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_ones = torch.ones_like(x_data) <span class="comment"># retains the properties of x_data but values are changed to one.</span></span><br><span class="line">x_rand = torch.rand_like(x_data, dtype=torch.<span class="built_in">float</span>) <span class="comment">#overrides the datatype of x_data, and values are changed. </span></span><br></pre></td></tr></table></figure>

<p>Output will be like:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Ones Tensor:</span><br><span class="line"> tensor([[1, 1],</span><br><span class="line">        [1, 1]])</span><br><span class="line"></span><br><span class="line">Random Tensor:</span><br><span class="line"> tensor([[0.8823, 0.9150],</span><br><span class="line">        [0.3829, 0.9593]])</span><br></pre></td></tr></table></figure>
</li>
<li><p>With random or constant values</p>
<p><strong>shape</strong> is a tuple of tensor dimensions. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">shape = (<span class="number">2</span>, <span class="number">3</span>,) <span class="comment"># The shape determines the dimensionality of the tensor</span></span><br><span class="line">rand_tensor = torch.rand(shape)</span><br><span class="line">ones_tensor = torch.ones(shape)</span><br><span class="line">zeros_tensor = torch.zeros(shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Random Tensor: \n <span class="subst">&#123;rand_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Ones Tensor: \n <span class="subst">&#123;ones_tensor&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Zeros Tensor: \n <span class="subst">&#123;zeros_tensor&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Random Tensor:</span><br><span class="line"> tensor([[0.3904, 0.6009, 0.2566],</span><br><span class="line">        [0.7936, 0.9408, 0.1332]])</span><br><span class="line"></span><br><span class="line">Ones Tensor:</span><br><span class="line"> tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]])</span><br><span class="line"></span><br><span class="line">Zeros Tensor:</span><br><span class="line"> tensor([[0., 0., 0.],</span><br><span class="line">        [0., 0., 0.]])</span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="2-2-Tensor-Attributes"><a href="#2-2-Tensor-Attributes" class="headerlink" title="2.2 Tensor Attributes"></a>2.2 Tensor Attributes</h5><p>Tensor has attributes as shape, datatype, and the device they are running on:</p>
<p>tensor.shape,   tensor.dtype,  tensor.device.</p>
<h5 id="2-3-Operations-of-Tensor"><a href="#2-3-Operations-of-Tensor" class="headerlink" title="2.3 Operations of Tensor"></a>2.3 Operations of Tensor</h5><ol>
<li><strong>Moving to GPU</strong></li>
</ol>
<p><code>tensor.to(&#39;cuda&#39;)</code>:  a PyTorch method that is used to move a tensor to a specific device. In this case, it’s moving the tensor to the GPU. </p>
<p>The argument <code>&#39;cuda&#39;</code> refers to the CUDA device, which is the parallel computing architecture developed by NVIDIA that is commonly used for deep learning.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># We move our tensor to the GPU if available</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">  tensor = tensor.to(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;tensor.device&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p><strong>Indexing and Slicing</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.ones(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">tensor[:,<span class="number">1</span>] = <span class="number">0</span> <span class="comment"># This will replace the second column&#x27;s values with 1. </span></span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Joining tensors</strong></p>
<p>You can use <code>torch.cat</code> to concatenate a sequence of tensors along a given dimension. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(t1)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure>

<p>Another way to join tensors is to use torch.stack. This need all tensors to be of the same size.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.stack(tensors, dim=<span class="number">0</span>, *, out=<span class="literal">None</span>) → Tensor</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create some tensors</span></span><br><span class="line">tensor1 = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">tensor2 = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Stack the tensors along a new dimension (default is dim=0)</span></span><br><span class="line">stacked_tensor = torch.stack([tensor1, tensor2])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(stacked_tensor)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1, 2, 3],</span><br><span class="line">        [4, 5, 6]])</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Multiplying tensors</strong></p>
<p>Multiplying can be element-wise**(Hadamard product)** and matrix wise**(Matrix product)**.</p>
<ol>
<li><p>element-wise:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This computes the element-wise product</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;tensor.mul(tensor) \n <span class="subst">&#123;tensor.mul(tensor)&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="comment"># Alternative syntax:</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;tensor * tensor \n <span class="subst">&#123;tensor * tensor&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor.mul(tensor)</span><br><span class="line"> tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br><span class="line"></span><br><span class="line">tensor * tensor</span><br><span class="line"> tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br></pre></td></tr></table></figure>
</li>
<li><p>matrix-wise:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;tensor.matmul(tensor.T) \n <span class="subst">&#123;tensor.matmul(tensor.T)&#125;</span> \n&quot;</span>)</span><br><span class="line"><span class="comment"># Alternative syntax:</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;tensor @ tensor.T \n <span class="subst">&#123;tensor @ tensor.T&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tensor.matmul(tensor.T)</span><br><span class="line"> tensor([[3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.]])</span><br><span class="line"></span><br><span class="line">tensor @ tensor.T</span><br><span class="line"> tensor([[3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.],</span><br><span class="line">        [3., 3., 3., 3.]])</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p><strong>In-place operations</strong></p>
<p>In-place and out-of-place: In-place will change the tensor immediately without creating a new one(memory-efficient);  out-of-place will create a new tensor with the result and leave the original tensor unchanged(less memory-efficient).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tensor, <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">tensor.add_(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(tensor)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.],</span><br><span class="line">        [1., 0., 1., 1.]])</span><br><span class="line"></span><br><span class="line">tensor([[6., 5., 6., 6.],</span><br><span class="line">        [6., 5., 6., 6.],</span><br><span class="line">        [6., 5., 6., 6.],</span><br><span class="line">        [6., 5., 6., 6.]])</span><br></pre></td></tr></table></figure></li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>Pytorch Introduction--Tensor</p><p><a href="http://example.com/2023/11/23/Pytorch-Introduction/">http://example.com/2023/11/23/Pytorch-Introduction/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Guangtian</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-11-23</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-11-23</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/pytorch/">pytorch</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2023/09/18/KNN-mechanism-for-machine-learning/"><span class="level-item">KNN mechanism for machine learning</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://example.com/2023/11/23/Pytorch-Introduction/';
            this.page.identifier = '2023/11/23/Pytorch-Introduction/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'https-guangtian0330-github-io-2' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Guangtian"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Guangtian</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Sudbury, ON.</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">8</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/guangtian0330" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/guangtian0330"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Android/"><span class="level-start"><span class="level-item">Android</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/algorithm/"><span class="level-start"><span class="level-item">algorithm</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/journal/"><span class="level-start"><span class="level-item">journal</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-23T20:37:00.000Z">2023-11-23</time></p><p class="title"><a href="/2023/11/23/Pytorch-Introduction/">Pytorch Introduction--Tensor</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-18T20:23:11.000Z">2023-09-18</time></p><p class="title"><a href="/2023/09/18/KNN-mechanism-for-machine-learning/">KNN mechanism for machine learning</a></p><p class="categories"><a href="/categories/algorithm/">algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-18T20:22:42.000Z">2023-09-18</time></p><p class="title"><a href="/2023/09/18/Audio-streaming-on-Android-AudioTrack-to-AHAL/">Audio streaming on Android:AudioTrack to AHAL</a></p><p class="categories"><a href="/categories/Android/">Android</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-18T20:22:07.000Z">2023-09-18</time></p><p class="title"><a href="/2023/09/18/Dynamic-Programming/">Dynamic Programming</a></p><p class="categories"><a href="/categories/algorithm/">algorithm</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-18T20:21:26.000Z">2023-09-18</time></p><p class="title"><a href="/2023/09/18/How-AudioServer-is-initialized-on-Android/">How AudioServer is initialized on Android</a></p><p class="categories"><a href="/categories/Android/">Android</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Andorid/"><span class="tag">Andorid</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Android/"><span class="tag">Android</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Audio/"><span class="tag">Audio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C/"><span class="tag">C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algorithm/"><span class="tag">algorithm</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/workshop/"><span class="tag">workshop</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Guangtian&#039;s BLOG" height="28"></a><p class="is-size-7"><span>&copy; 2023 Guangtian</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>